{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TM_test_DogLeash.ipynb","provenance":[],"authorship_tag":"ABX9TyPjubv9yWAdszAuj1DaqB5O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PyDgmgYJaGV","executionInfo":{"status":"ok","timestamp":1636771252395,"user_tz":-540,"elapsed":3473,"user":{"displayName":"이지은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giizn3q7dELb6bHU8On4xsRgxnXLnd-sEt9zCydQg=s64","userId":"07454465648744208728"}},"outputId":"25c45db3-4d86-422c-e616-0d3289c0e05f"},"source":["from keras.models import load_model\n","from PIL import Image, ImageOps\n","import numpy as np\n","\n","# Load the model\n","model = load_model('keras_model.h5')\n","\n","# Create the array of the right shape to feed into the keras model\n","# The 'length' or number of images you can put into the array is\n","# determined by the first position in the shape tuple, in this case 1.\n","data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n","# Replace this with the path to your image\n","image = Image.open('/content/t6.jfif')\n","#resize the image to a 224x224 with the same strategy as in TM2:\n","#resizing the image to be at least 224x224 and then cropping from the center\n","size = (224, 224)\n","image = ImageOps.fit(image, size, Image.ANTIALIAS)\n","\n","#turn the image into a numpy array\n","image_array = np.asarray(image)\n","# Normalize the image\n","normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n","# Load the image into the array\n","data[0] = normalized_image_array\n","\n","# run the inference\n","prediction = model.predict(data)\n","print(prediction)\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","[[9.9926263e-01 7.3738361e-04]]\n"]}]}]}